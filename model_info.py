# Информация о моделях
MODEL_DESCRIPTIONS = {
    "llama3-70b-8192": {
        "description": "Мощная модель для сложных задач. Отлично подходит для глубоких вопросов, анализа, объяснений и задач, требующих детального ответа.",
        "use_case": "Для вопросов вроде \"Объясни квантовую физику\" или \"Проанализируй этот текст\".",
        "limits": "30 запросов в минуту, 14,400 в день, 6,000 токенов в минуту, 500,000 токенов в день.",
        "features": "Может быть медленнее, чем другие модели, но даёт более точные и глубокие ответы."
    },
    "llama3-8b-8192": {
        "description": "Быстрая и лёгкая модель для простых вопросов. Подходит для быстрых ответов, коротких запросов и повседневных задач.",
        "use_case": "Для вопросов вроде \"Какая сегодня погода?\" или \"Сколько будет 2+2?\".",
        "limits": "30 запросов в минуту, 14,400 в день, 15,000 токенов в минуту, 500,000 токенов в день.",
        "features": "Быстрее, чем llama3-70b-8192, но менее точна в сложных задачах."
    },
    "deepseek-r1-distill-llama-70b": {
        "description": "Резервная модель без дневного лимита по токенам. Используется, если лимиты других моделей исчерпаны.",
        "use_case": "Подходит для любых задач, когда другие модели недоступны из-за лимитов.",
        "limits": "30 запросов в минуту, 14,400 в день, 6,000 токенов в минуту, без ограничения токенов в день.",
        "features": "Хороший баланс между скоростью и качеством, подходит для большинства задач."
    },
    "gemma2-9b-it": {
        "description": "Компактная модель от Google, хорошо подходит для общих вопросов и задач средней сложности.",
        "use_case": "Для вопросов вроде \"Расскажи о Древнем Риме\" или \"Как приготовить пиццу?\".",
        "limits": "30 запросов в минуту, 14,400 в день, 15,000 токенов в минуту, 500,000 токенов в день.",
        "features": "Быстрая и эффективная, но не такая мощная, как llama3-70b-8192. Хороший выбор для простых и средних задач."
    },
    "mistral-saba-24b": {
        "description": "Модель среднего размера, разработанная для универсальных задач. Обеспечивает хороший баланс между скоростью и качеством.",
        "use_case": "Для вопросов вроде \"Придумай короткий рассказ\" или \"Объясни, как работает интернет\".",
        "limits": "30 запросов в минуту, 1,000 в день, 6,000 токенов в минуту, 500,000 токенов в день.",
        "features": "Универсальная модель, но имеет более низкий лимит запросов в день (1,000), поэтому используйте её умеренно."
    }
}

# Доступные модели для выбора
AVAILABLE_MODELS = [
    "llama3-70b-8192",
    "llama3-8b-8192",
    "gemma2-9b-it",
    "mistral-saba-24b",
    "deepseek-r1-distill-llama-70b"
]

# Описание модели для распознавания голосовых сообщений
WHISPER_MODEL_INFO = {
    "description": "Модель для транскрипции голосовых сообщений в текст. Преобразует ваши голосовые сообщения в текст, чтобы я мог ответить на них.",
    "limits": "20 запросов в минуту, 2,000 в день, не более 2 часов аудио в час и 8 часов аудио в день.",
    "features": "Поддерживает русский язык и многие другие языки. Точная транскрипция, но ограничена по времени аудио."
}

# Максимальная длительность голосового сообщения в секундах
MAX_VOICE_DURATION = 300  # 5 минут

# Функция для получения информации о модели
def get_model_info(model_name):
    """Возвращает информацию о указанной модели"""
    return MODEL_DESCRIPTIONS.get(model_name, {
        "description": "Информация о модели отсутствует.",
        "use_case": "Нет данных",
        "limits": "Нет данных",
        "features": "Нет данных"
    })

# Функция для получения информации о всех моделях
def get_all_models_info():
    """Возвращает информацию о всех доступных моделях"""
    results = []
    for model_name in AVAILABLE_MODELS:
        info = get_model_info(model_name)
        results.append({
            "name": model_name,
            "description": info["description"],
            "use_case": info["use_case"],
            "limits": info["limits"],
            "features": info["features"]
        })
    return results